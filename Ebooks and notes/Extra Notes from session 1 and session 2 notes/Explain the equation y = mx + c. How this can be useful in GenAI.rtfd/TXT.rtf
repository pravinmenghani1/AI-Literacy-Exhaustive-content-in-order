{\rtf1\ansi\ansicpg1252\cocoartf2822
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Bold;\f1\froman\fcharset0 Times-Roman;\f2\fnil\fcharset0 STIXTwoMath-Regular;
\f3\fnil\fcharset134 STSongti-SC-Regular;\f4\fnil\fcharset0 AppleColorEmoji;\f5\fnil\fcharset0 AppleSymbols;
\f6\froman\fcharset0 TimesNewRomanPSMT;\f7\froman\fcharset0 Times-BoldItalic;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red109\green109\blue109;\red0\green0\blue255;
}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c50196\c50196\c50196;\cssrgb\c1680\c19835\c100000;
}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid301\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid501\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid601\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid701\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid801\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid9}
{\list\listtemplateid10\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid901\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid10}
{\list\listtemplateid11\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1001\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid1002\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid11}
{\list\listtemplateid12\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid12}
{\list\listtemplateid13\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid1202\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid13}
{\list\listtemplateid14\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid1302\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid14}
{\list\listtemplateid15\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1401\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid15}
{\list\listtemplateid16\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1501\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{circle\}}{\leveltext\leveltemplateid1502\'01\uc0\u9702 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid16}
{\list\listtemplateid17\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1601\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid17}
{\list\listtemplateid18\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1701\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid18}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}{\listoverride\listid10\listoverridecount0\ls10}{\listoverride\listid11\listoverridecount0\ls11}{\listoverride\listid12\listoverridecount0\ls12}{\listoverride\listid13\listoverridecount0\ls13}{\listoverride\listid14\listoverridecount0\ls14}{\listoverride\listid15\listoverridecount0\ls15}{\listoverride\listid16\listoverridecount0\ls16}{\listoverride\listid17\listoverridecount0\ls17}{\listoverride\listid18\listoverridecount0\ls18}}
\paperw11900\paperh16840\margl1440\margr1440\vieww38200\viewh20480\viewkind0
\deftab720
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs48 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Explain the equation y = mx + c. \outl0\strokewidth0 How this can be useful in GenAI?\outl0\strokewidth0 \strokec2 \
1. The Equation
\f1\b0 \

\f0\b y=mx+c\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 This is the equation of a 
\f0\b straight line
\f1\b0  in 2D space.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 	\'95
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 y: Predicted output (dependent variable).\
\ls1\ilvl0
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 	\'95
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 x: Input feature (independent variable).\
\ls1\ilvl0
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 m: The 
\f0\b slope
\f1\b0  or 
\f0\b weight
\f1\b0  (tells us how much 
\f2 y 
\f1 changes if 
\f2 x 
\f1 changes).\
\ls1\ilvl0
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 c: The 
\f0\b intercept
\f1\b0  or 
\f0\b bias
\f1\b0  (tells us where the line crosses the y-axis when x=0).\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 In machine learning, especially in 
\f0\b linear regression
\f1\b0 , this equation is the simplest model we use to predict an output from an input.\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b \cf0 \strokec2 2. Generalizing to Machine Learning Models\
\pard\pardeftab720\partightenfactor0

\f1\b0 \cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 y=w1 x1 +w2 x2 +
\f3 \'a1\'ad
\f1 +wn xn +b\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Where:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 w1 ,w2 ,\'85,wn = 
\f0\b weights
\f1\b0  (similar to 
\f2 m 
\f1 in the simple case).\
\ls2\ilvl0
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 	\'95
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 b = 
\f0\b bias term
\f1\b0  (similar to 
\f2 c
\f1 ).\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 This is the 
\f0\b hypothesis function
\f1\b0  (our model).\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b \cf0 \strokec2 3. What Do Weights and Bias Mean?\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls3\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Weights (w)
\f1\b0 : Control the importance of each input feature. A large weight means that feature strongly influences predictions.\
\ls3\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Bias (b)
\f1\b0 : Allows the model to shift predictions up or down, independent of input features. Without bias, the line must always pass through the origin (0,0), which is too restrictive.\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b \cf0 \strokec2 4. How Are Weights and Bias Calculated?\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 We don\'92t pick them manually; they are 
\f0\b learned during training
\f1\b0  by minimizing a 
\f0\b loss function
\f1\b0 .\
\pard\pardeftab720\partightenfactor0
\cf0 MSE=n1 i=1\uc0\u8721 n (yi \u8722 y^ i )2\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Where:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls4\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 yi : Actual value.\
\ls4\ilvl0
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 y^ i : Predicted value (mxi +c).\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 The learning process:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls5\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Start with random weights and bias.\
\ls5\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Compute predictions and calculate the error (loss).\
\ls5\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Use an optimization method (like 
\f0\b gradient descent
\f1\b0 ) to adjust weights and bias so the error decreases.\
\ls5\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Repeat until the model converges (error stops improving significantly).\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b \cf0 \strokec2 5. Root Mean Square Error (RMSE)\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 RMSE is a commonly used metric to evaluate regression models. It is the square root of the average squared differences between predictions and actual values:\
\pard\pardeftab720\partightenfactor0
\cf0 RMSE=n1 i=1\uc0\u8721 n (yi \u8722 y^ i )2\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 Interpretation
\f1\b0 :\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls6\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 RMSE tells us, on average, how far predictions are from the actual values.\
\ls6\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 A lower RMSE = better fit.\
\ls6\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Units of RMSE are the same as the output variable y, making it more interpretable than MSE.\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b \cf0 \strokec2 6. Intuitive Example\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 Suppose we want to predict 
\f0\b house prices
\f1\b0  based on 
\f0\b square footage
\f1\b0 .\
Equation:\
\pard\pardeftab720\partightenfactor0
\cf0 y^ =mx+c\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls7\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 	\'95
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 x: square footage\
\ls7\ilvl0
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 y^ : predicted house price\
\ls7\ilvl0
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 m: how much price increases per additional square foot\
\ls7\ilvl0
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 c: base price of a house (even with zero area)\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 During training:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls8\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The model adjusts m and 
\f2 c 
\f1 until predicted prices closely match real prices.\
\ls8\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 RMSE tells us the typical difference between predicted and actual house prices.\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa240\partightenfactor0

\f4 \cf0 \strokec2 \uc0\u9989 
\f1  
\f0\b Summary
\f1\b0 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls9\ilvl0
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 y=mx+c is the foundation of 
\f0\b linear regression
\f1\b0  in ML.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls9\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Weights (m, w)
\f1\b0  show feature importance.\
\ls9\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Bias (c, b)
\f1\b0  shifts the prediction baseline.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls9\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 They are learned by minimizing a 
\f0\b loss function
\f1\b0  (usually MSE).\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls9\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 RMSE
\f1\b0  is an evaluation metric showing the average prediction error in the same units as the output.\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f0\b \cf0 How this will be useful in GenAI?\cf3 \strokec3 \
\pard\pardeftab720\sa298\partightenfactor0
\cf0 \strokec2 1. Numerical Example: Linear Regression\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 Suppose we want to predict 
\f0\b house price ($1000s)
\f1\b0  based on 
\f0\b house size (square feet)
\f1\b0 .\
\pard\pardeftab720\sa280\partightenfactor0

\f0\b \cf0 Training Data (simplified):\

\itap1\trowd \taflags0 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth1320\clftsWidth3 \clmart10 \clmarl10 \clmarb10 \clmarr10 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadb20 \clpadr20 \gaph\cellx4320
\clvertalc \clshdrawnil \clwWidth1673\clftsWidth3 \clmart10 \clmarl10 \clmarb10 \clmarr10 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadb20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\qc\partightenfactor0
\cf0 Size (x, sq.ft)\cell 
\pard\intbl\itap1\pardeftab720\qc\partightenfactor0
\cf0 Price (y, $1000s)\cell \row

\itap1\trowd \taflags0 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth1320\clftsWidth3 \clmart10 \clmarl10 \clmarb10 \clmarr10 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadb20 \clpadr20 \gaph\cellx4320
\clvertalc \clshdrawnil \clwWidth1673\clftsWidth3 \clmart10 \clmarl10 \clmarb10 \clmarr10 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadb20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0

\f1\b0 \cf0 1000\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 150\cell \row

\itap1\trowd \taflags0 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth1320\clftsWidth3 \clmart10 \clmarl10 \clmarb10 \clmarr10 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadb20 \clpadr20 \gaph\cellx4320
\clvertalc \clshdrawnil \clwWidth1673\clftsWidth3 \clmart10 \clmarl10 \clmarb10 \clmarr10 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadb20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 1500\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 200\cell \row

\itap1\trowd \taflags0 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth1320\clftsWidth3 \clmart10 \clmarl10 \clmarb10 \clmarr10 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadb20 \clpadr20 \gaph\cellx4320
\clvertalc \clshdrawnil \clwWidth1673\clftsWidth3 \clmart10 \clmarl10 \clmarb10 \clmarr10 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadb20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 2000\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 250\cell \row

\itap1\trowd \taflags0 \trgaph108\trleft-108 \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth1320\clftsWidth3 \clmart10 \clmarl10 \clmarb10 \clmarr10 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadb20 \clpadr20 \gaph\cellx4320
\clvertalc \clshdrawnil \clwWidth1673\clftsWidth3 \clmart10 \clmarl10 \clmarb10 \clmarr10 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadt20 \clpadl20 \clpadb20 \clpadr20 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 2500\cell 
\pard\intbl\itap1\pardeftab720\partightenfactor0
\cf0 300\cell \lastrow\row
\pard\pardeftab720\sa240\partightenfactor0
\cf0 Looks like a clear straight-line relationship.\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa280\partightenfactor0

\f0\b \cf0 \strokec2 Step 1: Hypothesis Equation\
\pard\pardeftab720\partightenfactor0

\f1\b0 \cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 y^ =mx+c\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 We need to find\
m (weight/slope) and
\f2 \
\pard\pardeftab720\partightenfactor0

\f1 \cf0 \
\pard\pardeftab720\sa240\partightenfactor0
\cf0 c (bias/intercept).\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf3 {{\NeXTGraphic Pasted Graphic.png \width21940 \height10860 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\
\pard\pardeftab720\partightenfactor0
\cf3 {{\NeXTGraphic Pasted Graphic 1.png \width23880 \height15060 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\partightenfactor0
\cf3 \
\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \strokec2 Since all predictions are exact, errors = 0.\uc0\u8232 So RMSE = 0.\
In real-world data, RMSE > 0.
\fs24 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa321\partightenfactor0

\f0\b\fs48 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f1\b0 \cf3 \strokec3 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b \cf0 \strokec2 2. Why Is This Useful in Machine Learning?\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls10\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Weights (m)
\f1\b0  = how strongly a feature influences predictions.\
\ls10\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Bias (c)
\f1\b0  = baseline prediction when features are zero.\
\ls10\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 RMSE
\f1\b0  = how well the model performs.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 This foundation is not just for simple regression; it\'92s the 
\f0\b mathematical core of all neural networks
\f1\b0 .\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b \cf0 \strokec2 3. Connection to Generative AI (GenAI)\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 Now let\'92s bridge it:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls11\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Linear regression is the starting point.
\f1\b0 \uc0\u8232 In GenAI models (like GPT), instead of one weight and one bias, you have 
\f0\b billions of weights and biases
\f1\b0 . Each weight adjusts how much importance is given to input tokens (words, pixels, etc.).\
\ls11\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Equation scales up.
\f1\b0 \uc0\u8232 In neural networks, the equation becomes:\u8232 
\f2 \uc0\u8232 \u8232 
\f1 y^ =W
\f5 \uc0\u8901 
\f1 X+b\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls11\ilvl1
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 W: weight matrix\
\ls11\ilvl1
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 X: input vector (features, words, image pixels)\
\ls11\ilvl1
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 b: bias vector\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls11\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Instead of one line, the network learns 
\f0\b complex functions
\f1\b0  through many layers.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls11\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Error Minimization.
\f1\b0 \uc0\u8232 Just like we minimized RMSE for house prices, GenAI models minimize a loss function (like cross-entropy) during training.\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa240\partightenfactor0
\ls11\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 For GPT: predict the next word in a sentence.\
\ls11\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Error = difference between predicted word probabilities and actual word.\
\ls11\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Millions of updates adjust weights/biases.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls11\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Generative Power Comes from Scale.
\f1\b0 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa240\partightenfactor0
\ls11\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Linear regression: simple prediction (e.g., house prices).\
\ls11\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 GenAI: same principle but scaled with billions of parameters 
\f6 \uc0\u8594 
\f1  can generate human-like text, images, or music.\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa240\partightenfactor0

\f4 \cf0 \strokec2 \uc0\u9989 
\f1  
\f0\b Key Insight:
\f1\b0 \uc0\u8232 The humble\
y=mx+c is the seed of every AI model. GenAI is just a massively scaled version where:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls12\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Inputs = words/images\
\ls12\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Weights = billions of learned values\
\ls12\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Bias = adjustments for flexibility\
\ls12\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Loss minimization = similar idea (but more complex than RMSE)\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\partightenfactor0

\f7\i\b \cf4 \strokec2 How this equation is useful in GenAI?\
\pard\pardeftab720\partightenfactor0

\f1\i0\b0 \cf0 y = mx + c\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 y=mx+c is useful in Generative AI (GenAI).
\f1\b0 \
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b \cf0 \strokec2 1. Core Mathematical Building Block\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls13\ilvl0
\f1\b0 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In 
\f0\b linear regression
\f1\b0 , 
\f2 \uc0\u8232 \u8232 
\f1 y=mx+c is just a line.\
\ls13\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In 
\f0\b deep learning
\f1\b0 , the same structure becomes:\uc0\u8232 
\f2 \uc0\u8232 \u8232 
\f1 y=W
\f5 \uc0\u8901 
\f1 X+b where:\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls13\ilvl1
\f2 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 W = weights (like slope m, but now as a matrix)\
\ls13\ilvl1
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 X = input features (text tokens, pixels, audio samples)\
\ls13\ilvl1
\f2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u9702 	}
\f1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 b = bias (like intercept c, but now for multiple neurons)\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 This is applied repeatedly in each 
\f0\b neuron
\f1\b0  of a neural network. A large GenAI model is essentially millions (or billions) of these tiny equations stacked together.\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b \cf0 \strokec2 2. How It Powers Generative AI\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls14\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Word Prediction (Text GenAI, e.g., GPT)
\f1\b0 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa240\partightenfactor0
\ls14\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Input = previous words (converted into vectors).\
\ls14\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Equation \uc0\u8232 
\f2 \uc0\u8232 
\f1 y=W
\f5 \uc0\u8901 
\f1 X+b 
\f6 \uc0\u8594 
\f1  computes probabilities for the next word.\
\ls14\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Example: After \'93Once upon a\'94, model predicts 
\f0\b \'93time\'94
\f1\b0  with the highest probability.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls14\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Image Generation (e.g., DALL\'b7E, Stable Diffusion)
\f1\b0 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa240\partightenfactor0
\ls14\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Input = noise or text description.\
\ls14\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Equation maps noise/features into patterns (shapes, textures).\
\ls14\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Repeatedly adjusts pixels until a realistic image forms.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls14\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Music / Speech Generation
\f1\b0 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa240\partightenfactor0
\ls14\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Inputs = sound wave features.\
\ls14\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Weighted equations adjust frequencies, tones, and rhythm.\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b \cf0 \strokec2 3. Why Bias and Weights Matter in GenAI\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls15\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Weights
\f1\b0  
\f6 \uc0\u8594 
\f1  Learn complex relationships (e.g., \'93cat\'94 relates to \'93whiskers\'94 or \'93meow\'94).\
\ls15\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Bias
\f1\b0  
\f6 \uc0\u8594 
\f1  Allows flexibility (e.g., shifting meaning of a word depending on context).\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls15\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Without bias, every neuron would be forced through zero, limiting expressiveness.\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b \cf0 \strokec2 4. Error Minimization (like RMSE, but scaled up)\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls16\ilvl0
\f1\b0 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In regression, we minimize 
\f0\b RMSE
\f1\b0 .\
\ls16\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In GenAI, we minimize more advanced loss functions (e.g., 
\f0\b cross-entropy loss
\f1\b0  for text).\
\ls16\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 But the idea is the same:\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa240\partightenfactor0
\ls16\ilvl1\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Compare predictions with actual outcomes.\
\ls16\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Adjust weights and bias.\
\ls16\ilvl1\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	
\f6 \uc0\u9702 
\f1 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Repeat billions of times.\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b \cf0 \strokec2 5. The Bridge: From Line to Creativity\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls17\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Linear regression
\f1\b0 : predicts a number.\
\ls17\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Deep learning
\f1\b0 : predicts probabilities.\
\ls17\ilvl0
\f0\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 GenAI
\f1\b0 : uses those probabilities to 
\f0\b generate new content
\f1\b0  (text, images, music).\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 So, even though GenAI looks magical, at its heart it is just a vast network of 
\f0\b billions of little
\f2\b0 \
\pard\pardeftab720\partightenfactor0

\f1 \cf0 \
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf0 y=mx+c equations working together
\f1\b0 .\
\pard\pardeftab720\partightenfactor0
\cf3 \strokec3 \
\pard\pardeftab720\sa240\partightenfactor0

\f4 \cf0 \strokec2 \uc0\u9989 
\f1  
\f0\b Summary:
\f1\b0 \uc0\u8232 The simple equation
\f2 \
\pard\pardeftab720\partightenfactor0

\f1 \cf0 \
\pard\pardeftab720\sa240\partightenfactor0
\cf0 y=mx+c is the 
\f0\b DNA of GenAI
\f1\b0 . It provides the basic mechanism for:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls18\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 transforming inputs into outputs,\
\ls18\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 learning relationships via weights and bias,\
\ls18\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 and minimizing error through optimization.\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 By stacking and combining millions of such linear transformations, GenAI models can generate entirely new text, images, or sounds.\
}